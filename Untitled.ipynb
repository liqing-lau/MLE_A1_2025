{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "64a8cd3a-c496-4a3f-9ce2-adbf06bf8942",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "from datetime import datetime, timedelta\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import pprint\n",
    "import pyspark\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.window import Window\n",
    "import argparse\n",
    "\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql.types import StringType, IntegerType, FloatType, DateType, BooleanType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cbf1b5ee-0009-4e44-9683-145d3a9161a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"data/\"\n",
    "clickstream = path + \"feature_clickstream.csv\"\n",
    "attributes = path + \"features_attributes.csv\"\n",
    "financials = path + \"features_financials.csv\"\n",
    "loan_daily = path + \"lms_loan_daily.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b0cb8f03-ef3e-4815-b9ed-5e6c5fd84646",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize SparkSession\n",
    "spark = pyspark.sql.SparkSession.builder \\\n",
    "    .appName(\"dev\") \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Set log level to ERROR to hide warnings\n",
    "spark.sparkContext.setLogLevel(\"ERROR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5d5c0eef-dda6-4470-96a1-497c4c771502",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_first_of_month_dates(start_date_str, end_date_str):\n",
    "    # Convert the date strings to datetime objects\n",
    "    start_date = datetime.strptime(start_date_str, \"%Y-%m-%d\")\n",
    "    end_date = datetime.strptime(end_date_str, \"%Y-%m-%d\")\n",
    "    \n",
    "    # List to store the first of month dates\n",
    "    first_of_month_dates = []\n",
    "\n",
    "    # Start from the first of the month of the start_date\n",
    "    current_date = datetime(start_date.year, start_date.month, 1)\n",
    "\n",
    "    while current_date <= end_date:\n",
    "        # Append the date in yyyy-mm-dd format\n",
    "        first_of_month_dates.append(current_date.strftime(\"%Y-%m-%d\"))\n",
    "        \n",
    "        # Move to the first of the next month\n",
    "        if current_date.month == 12:\n",
    "            current_date = datetime(current_date.year + 1, 1, 1)\n",
    "        else:\n",
    "            current_date = datetime(current_date.year, current_date.month + 1, 1)\n",
    "\n",
    "    return first_of_month_dates\n",
    "\n",
    "start_date_str = \"2023-01-01\"\n",
    "end_date_str = \"2024-12-01\"\n",
    "\n",
    "dates_str_lst = generate_first_of_month_dates(start_date_str, end_date_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ae31642a-67e4-407c-85de-8fd100f426aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_bronze_table_with_date(filepath, snapshot_date_str, bronze_directory, spark): \n",
    "    snapshot_date = datetime.strptime(snapshot_date_str, \"%Y-%m-%d\")\n",
    "    filename = filepath.split(\"/\")[-1][:-4]\n",
    "    \n",
    "    # load data\n",
    "    df = spark.read.csv(filepath, \n",
    "                        header=True, \n",
    "                        inferSchema=True).filter(col('snapshot_date') == snapshot_date)\n",
    "\n",
    "    # save bronze table to datamart\n",
    "    partition_name = \"bronze_\" + filename + \"_\" + snapshot_date_str.replace('-','_') + '.csv'\n",
    "    bronze_filepath = bronze_directory + partition_name\n",
    "\n",
    "    # make directory if it doesnt exists\n",
    "    if not os.path.exists(bronze_directory):\n",
    "        os.makedirs(bronze_directory)\n",
    "        \n",
    "    df.toPandas().to_csv(bronze_filepath, index=False)\n",
    "    print('saved to:', bronze_filepath)\n",
    "\n",
    "    return df\n",
    "\n",
    "def process_bronze_table(filepath, bronze_directory, spark): \n",
    "    filename = filepath.split(\"/\")[-1][:-4]\n",
    "    \n",
    "    # load data\n",
    "    df = spark.read.csv(filepath, \n",
    "                        header=True, \n",
    "                        inferSchema=True)\n",
    "\n",
    "    # save bronze table to datamart\n",
    "    partition_name = \"bronze_\" + filename + '.csv'\n",
    "    bronze_filepath = bronze_directory + partition_name\n",
    "\n",
    "    # make directory if it doesnt exists\n",
    "    if not os.path.exists(bronze_directory):\n",
    "        os.makedirs(bronze_directory)\n",
    "        \n",
    "    df.toPandas().to_csv(bronze_filepath, index=False)\n",
    "    print('saved to:', bronze_filepath)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "32ff1f47-0ee7-415e-8197-b0996a9482c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved to: datamart/bronze/clickstream/bronze_feature_clickstream_2023_01_01.csv\n",
      "saved to: datamart/bronze/lms/bronze_lms_loan_daily_2023_01_01.csv\n",
      "saved to: datamart/bronze/attribute/bronze_features_attributes.csv\n",
      "saved to: datamart/bronze/financial/bronze_features_financials.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[Customer_ID: string, Annual_Income: string, Monthly_Inhand_Salary: double, Num_Bank_Accounts: int, Num_Credit_Card: int, Interest_Rate: int, Num_of_Loan: string, Type_of_Loan: string, Delay_from_due_date: int, Num_of_Delayed_Payment: string, Changed_Credit_Limit: string, Num_Credit_Inquiries: double, Credit_Mix: string, Outstanding_Debt: string, Credit_Utilization_Ratio: double, Credit_History_Age: string, Payment_of_Min_Amount: string, Total_EMI_per_month: double, Amount_invested_monthly: string, Payment_Behaviour: string, Monthly_Balance: string, snapshot_date: date]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snapshotdate = \"2023-01-01\"\n",
    "\n",
    "process_bronze_table_with_date(clickstream, snapshotdate, \"datamart/bronze/clickstream/\", spark)\n",
    "process_bronze_table_with_date(loan_daily, snapshotdate, \"datamart/bronze/lms/\", spark)\n",
    "process_bronze_table(attributes, \"datamart/bronze/attribute/\", spark)\n",
    "process_bronze_table(financials, \"datamart/bronze/financial/\", spark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f41ec3d9-3070-4934-a1f4-fb5a67a573fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded from: datamart/bronze/clickstream/bronze_feature_clickstream_2023_01_01.csv row count: 8974\n",
      "saved to: datamart/silver/clickstream/silver_feature_clickstream_2023_01_01.parquet\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[fe_1: int, fe_2: int, fe_3: int, fe_4: int, fe_5: int, fe_6: int, fe_7: int, fe_8: int, fe_9: int, fe_10: int, fe_11: int, fe_12: int, fe_13: int, fe_14: int, fe_15: int, fe_16: int, fe_17: int, fe_18: int, fe_19: int, fe_20: int, Customer_ID: string, snapshot_date: date]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def process_silver_clickstream_table(snapshot_date_str, bronze_dir, silver_dir, spark): \n",
    "    snapshot_date = datetime.strptime(snapshot_date_str, \"%Y-%m-%d\")\n",
    "    \n",
    "    filename = \"bronze_feature_clickstream_\" + snapshot_date_str.replace('-','_') + '.csv'\n",
    "    filepath = bronze_dir + filename\n",
    "    df = spark.read.csv(filepath, header=True, inferSchema=True)\n",
    "    print('loaded from:', filepath, 'row count:', df.count())\n",
    "\n",
    "    # clean data: enforce schema / data type\n",
    "    # Dictionary specifying columns and their desired datatypes\n",
    "    column_type_map = {\"fe_1\": IntegerType(),\n",
    "                       'fe_2': IntegerType(),\n",
    "                       'fe_3': IntegerType(),\n",
    "                       'fe_4': IntegerType(),\n",
    "                       'fe_5': IntegerType(),\n",
    "                       'fe_6': IntegerType(),\n",
    "                       'fe_7': IntegerType(),\n",
    "                       'fe_8': IntegerType(),\n",
    "                       'fe_9': IntegerType(),\n",
    "                       'fe_10': IntegerType(),\n",
    "                       'fe_11': IntegerType(),\n",
    "                       'fe_12': IntegerType(),\n",
    "                       'fe_13': IntegerType(),\n",
    "                       'fe_14': IntegerType(),\n",
    "                       'fe_15': IntegerType(),\n",
    "                       'fe_16': IntegerType(),\n",
    "                       'fe_17': IntegerType(),\n",
    "                       'fe_18': IntegerType(),\n",
    "                       'fe_19': IntegerType(),\n",
    "                       'fe_20': IntegerType(),\n",
    "                       \"Customer_ID\": StringType(),\n",
    "                       \"snapshot_date\": DateType()\n",
    "                    }\n",
    "\n",
    "    for column, new_type in column_type_map.items():\n",
    "        df = df.withColumn(column, col(column).cast(new_type))\n",
    "\n",
    "    if not os.path.exists(silver_dir):\n",
    "        os.makedirs(silver_dir)\n",
    "\n",
    "    # save silver table - IRL connect to database to write\n",
    "    filename = \"silver_feature_clickstream_\" + snapshot_date_str.replace('-','_') + '.parquet'\n",
    "    filepath = silver_dir + filename\n",
    "    df.write.mode(\"overwrite\").parquet(filepath)\n",
    "    print('saved to:', filepath)\n",
    "    \n",
    "    return df\n",
    "\n",
    "snapshotdate = \"2023-01-01\"\n",
    "process_silver_clickstream_table(snapshotdate, \n",
    "                                 \"datamart/bronze/clickstream/\", \n",
    "                                 \"datamart/silver/clickstream/\", \n",
    "                                 spark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "77fe2c2c-c651-4ef9-92a3-a47339a0a9ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded from: datamart/bronze/attribute/bronze_features_attributes.csv row count: 12500\n",
      "saved to: datamart/silver/attribute/silver_feature_attributes.parquet\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[Customer_ID: string, Name: string, Age: int, SSN: string, Occupation: string, snapshot_date: date, duplicate_ssn: boolean, duplicate_name_ssn: boolean, age_typo: boolean]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def process_silver_attribute_table(bronze_dir, silver_dir, spark): \n",
    "    filepath = bronze_dir + \"bronze_features_attributes.csv\"\n",
    "    df = spark.read.csv(filepath, header=True, inferSchema=True)\n",
    "    print('loaded from:', filepath, 'row count:', df.count())\n",
    "\n",
    "    # clean data: strip and replace alphanumeric for name, age and ssn\n",
    "    df = df.withColumn(\"Name\", F.trim(F.col(\"Name\")))\n",
    "    df = df.withColumn(\"Name\", F.regexp_replace(\"Name\", \"[^A-Za-z ]\", \"\"))\n",
    "    df = df.withColumn(\"SSN\", F.regexp_replace(F.col(\"SSN\"), r\"\\s+\", \"\"))\n",
    "    df = df.withColumn(\"Age\", F.regexp_replace(\"Age\", \"[^0-9]\", \"\"))\n",
    "\n",
    "    # clean data: enforce schema / data type\n",
    "    # Dictionary specifying columns and their desired datatypes\n",
    "    column_type_map = {\"Customer_ID\": StringType(),\n",
    "                       \"Name\": StringType(),\n",
    "                       'Age': IntegerType(),\n",
    "                       'SSN': StringType(),\n",
    "                       \"snapshot_date\": DateType()\n",
    "                      }\n",
    "\n",
    "    for column, new_type in column_type_map.items():\n",
    "        df = df.withColumn(column, col(column).cast(new_type))\n",
    "\n",
    "    # augment data: duplicated ssn\n",
    "    w = Window.partitionBy(\"SSN\")\n",
    "    df = df.withColumn(\"duplicate_ssn\", (F.count(\"*\").over(w) > 1).cast(BooleanType()))\n",
    "    \n",
    "    # augment data: duplicated name and ssn\n",
    "    w = Window.partitionBy(\"Name\", \"SSN\")\n",
    "    df = df.withColumn(\"duplicate_name_ssn\", (F.count(\"*\").over(w) > 1).cast(BooleanType()))\n",
    "\n",
    "    # augment data: potential age typo (bleow 18 and above 100)\n",
    "    df = df.withColumn(\"age_typo\", (F.col(\"Age\") < 0) | (F.col(\"Age\") > 100).cast(BooleanType()))\n",
    "    \n",
    "    if not os.path.exists(silver_dir):\n",
    "        os.makedirs(silver_dir)\n",
    "\n",
    "    # save silver table - IRL connect to database to write\n",
    "    filepath = silver_dir + \"silver_feature_attributes.parquet\"\n",
    "    df.write.mode(\"overwrite\").parquet(filepath)\n",
    "    print('saved to:', filepath)\n",
    "    \n",
    "    return df\n",
    "\n",
    "process_silver_attribute_table(\"datamart/bronze/attribute/\", \n",
    "                               \"datamart/silver/attribute/\", \n",
    "                               spark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "9bcf1996-f2fc-40ec-87ee-8d1bb13ef377",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded from: datamart/bronze/financial/bronze_features_financials.csv row count: 12500\n",
      "saved to: datamart/silver/financial/silver_feature_financials.parquet\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[Customer_ID: string, Annual_Income: float, Monthly_Inhand_Salary: float, Num_Bank_Accounts: float, Num_Credit_Card: float, Interest_Rate: float, Num_of_Loan: float, Type_of_Loan: string, Delay_from_due_date: float, Num_of_Delayed_Payment: float, Changed_Credit_Limit: float, Num_Credit_Inquiries: float, Credit_Mix: string, Outstanding_Debt: float, Credit_Utilization_Ratio: float, Credit_History_Age: string, Payment_of_Min_Amount: string, Total_EMI_per_month: float, Amount_invested_monthly: float, Payment_Behaviour: string, Monthly_Balance: float, snapshot_date: date, Negative_Num_of_Delayed_Payment: boolean, Negative_Changed_Credit_Limit: boolean, Negative_Delay_from_due_date: boolean, Negative_Num_of_Loan: boolean, Negative_Num_Bank_Accounts: boolean, No_bank_accounts: boolean]"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def process_silver_financial_table(bronze_dir, silver_dir, spark): \n",
    "    filepath = bronze_dir + \"bronze_features_financials.csv\"\n",
    "    df = spark.read.csv(filepath, header=True, inferSchema=True)\n",
    "    print('loaded from:', filepath, 'row count:', df.count())\n",
    "\n",
    "    df = df.withColumn(\"Type_of_Loan\", F.lower(F.col(\"Type_of_Loan\")))\n",
    "    \n",
    "    df = df.withColumn(\"Credit_Mix\", \n",
    "                       F.when(F.col(\"Credit_Mix\") == \"_\", None)\n",
    "                       .otherwise(F.col(\"Credit_Mix\")))\n",
    "    \n",
    "    df = df.withColumn(\"Payment_Behaviour\", \n",
    "                       F.when(F.col(\"Payment_Behaviour\") == \"!@9#%8\", \"Unknown\")\n",
    "                       .otherwise(F.col(\"Payment_Behaviour\")))\n",
    "\n",
    "    # clean data: enforce schema / data type\n",
    "    cleaning_rules = {\"Annual_Income\": \"[^0-9.]\",\n",
    "                      \"Num_of_Loan\": r\"[^0-9.\\-]\",\n",
    "                      \"Num_of_Delayed_Payment\": r\"[^0-9.\\-]\",\n",
    "                      \"Changed_Credit_Limit\": r\"[^0-9.\\-]\",\n",
    "                      \"Outstanding_Debt\": \"[^0-9.]\",\n",
    "                      \"Amount_invested_monthly\": \"[^0-9.]\",\n",
    "                      \"Monthly_Balance\": \"[^0-9.]\",\n",
    "                    }\n",
    "    for column, value in cleaning_rules.items(): \n",
    "        df = df.withColumn(column, F.regexp_replace(column, value, \"\"))\n",
    "    \n",
    "    # Dictionary specifying columns and their desired datatypes\n",
    "    column_type_map = {'Customer_ID': StringType(),\n",
    "                        'Annual_Income': FloatType(),\n",
    "                        'Monthly_Inhand_Salary': FloatType(),\n",
    "                        'Num_Bank_Accounts': FloatType(),\n",
    "                        'Num_Credit_Card': FloatType(),\n",
    "                        'Interest_Rate': FloatType(),\n",
    "                        'Num_of_Loan': FloatType(),\n",
    "                        'Type_of_Loan': StringType(),\n",
    "                        'Delay_from_due_date': FloatType(),\n",
    "                        'Num_of_Delayed_Payment': FloatType(),\n",
    "                        'Changed_Credit_Limit': FloatType(),\n",
    "                        'Num_Credit_Inquiries': FloatType(),\n",
    "                        'Credit_Mix': StringType(),\n",
    "                        'Outstanding_Debt': FloatType(),\n",
    "                        'Credit_Utilization_Ratio': FloatType(),\n",
    "                        'Credit_History_Age': StringType(),\n",
    "                        'Payment_of_Min_Amount': StringType(),\n",
    "                        'Total_EMI_per_month': FloatType(),\n",
    "                        'Amount_invested_monthly': FloatType(),\n",
    "                        'Payment_Behaviour': StringType(),\n",
    "                        'Monthly_Balance': FloatType(),\n",
    "                        'snapshot_date': DateType()\n",
    "                        }\n",
    "\n",
    "    for column, new_type in column_type_map.items():          \n",
    "        df = df.withColumn(column, col(column).cast(new_type))\n",
    "\n",
    "    # augment data: negative values\n",
    "    df = df.withColumn(\"Negative_Num_of_Delayed_Payment\", \n",
    "                       (F.col(\"Num_of_Delayed_Payment\") < 0).cast(BooleanType()))\n",
    "    \n",
    "    df = df.withColumn(\"Negative_Changed_Credit_Limit\", \n",
    "                       (F.col(\"Changed_Credit_Limit\") < 0).cast(BooleanType()))\n",
    "\n",
    "    df = df.withColumn(\"Negative_Delay_from_due_date\", \n",
    "                       (F.col(\"Delay_from_due_date\") < 0).cast(BooleanType()))\n",
    "\n",
    "    df = df.withColumn(\"Negative_Num_of_Loan\", \n",
    "                       (F.col(\"Num_of_Loan\") < 0).cast(BooleanType()))\n",
    "\n",
    "    df = df.withColumn(\"Negative_Num_Bank_Accounts\", \n",
    "                       (F.col(\"Num_Bank_Accounts\") < 0).cast(BooleanType()))\n",
    "\n",
    "    df = df.withColumn(\"No_bank_accounts\", \n",
    "                       (F.col(\"Num_Bank_Accounts\") == 0).cast(BooleanType()))\n",
    "\n",
    "    if not os.path.exists(silver_dir):\n",
    "        os.makedirs(silver_dir)\n",
    "    \n",
    "    # save silver table - IRL connect to database to write\n",
    "    filepath = silver_dir + \"silver_feature_financials.parquet\"\n",
    "    df.write.mode(\"overwrite\").parquet(filepath)\n",
    "    print('saved to:', filepath)\n",
    "    \n",
    "    return df\n",
    "\n",
    "process_silver_financial_table(\"datamart/bronze/financial/\", \n",
    "                               \"datamart/silver/financial/\", \n",
    "                               spark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "0dc0e582-7ed5-4f6c-ac56-f1909531bab3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded from: datamart/bronze/lms/bronze_lms_loan_daily_2023_01_01.csv row count: 530\n",
      "saved to: datamart/silver/lms/silver_lms_loan_daily_2023_01_01.parquet\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[loan_id: string, Customer_ID: string, loan_start_date: date, tenure: int, installment_num: int, loan_amt: float, due_amt: float, paid_amt: float, overdue_amt: float, balance: float, snapshot_date: date, mob: int, installments_missed: int, first_missed_date: date, dpd: int]"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def process_silver_lms_table(snapshot_date_str, bronze_lms_directory, silver_loan_daily_directory, spark):\n",
    "    # prepare arguments\n",
    "    snapshot_date = datetime.strptime(snapshot_date_str, \"%Y-%m-%d\")\n",
    "    \n",
    "    # connect to bronze table\n",
    "    partition_name = \"bronze_lms_loan_daily_\" + snapshot_date_str.replace('-','_') + '.csv'\n",
    "    filepath = bronze_lms_directory + partition_name\n",
    "    df = spark.read.csv(filepath, header=True, inferSchema=True)\n",
    "    print('loaded from:', filepath, 'row count:', df.count())\n",
    "\n",
    "    # clean data: enforce schema / data type\n",
    "    # Dictionary specifying columns and their desired datatypes\n",
    "    column_type_map = {\n",
    "        \"loan_id\": StringType(),\n",
    "        \"Customer_ID\": StringType(),\n",
    "        \"loan_start_date\": DateType(),\n",
    "        \"tenure\": IntegerType(),\n",
    "        \"installment_num\": IntegerType(),\n",
    "        \"loan_amt\": FloatType(),\n",
    "        \"due_amt\": FloatType(),\n",
    "        \"paid_amt\": FloatType(),\n",
    "        \"overdue_amt\": FloatType(),\n",
    "        \"balance\": FloatType(),\n",
    "        \"snapshot_date\": DateType(),\n",
    "    }\n",
    "\n",
    "    for column, new_type in column_type_map.items():\n",
    "        df = df.withColumn(column, col(column).cast(new_type))\n",
    "\n",
    "    # augment data: add month on book\n",
    "    df = df.withColumn(\"mob\", col(\"installment_num\").cast(IntegerType()))\n",
    "\n",
    "    # augment data: add days past due\n",
    "    df = df.withColumn(\"installments_missed\", F.ceil(col(\"overdue_amt\") / col(\"due_amt\")).cast(IntegerType())).fillna(0)\n",
    "    df = df.withColumn(\"first_missed_date\", F.when(col(\"installments_missed\") > 0, F.add_months(col(\"snapshot_date\"), -1 * col(\"installments_missed\"))).cast(DateType()))\n",
    "    df = df.withColumn(\"dpd\", F.when(col(\"overdue_amt\") > 0.0, F.datediff(col(\"snapshot_date\"), col(\"first_missed_date\"))).otherwise(0).cast(IntegerType()))\n",
    "\n",
    "    # save silver table - IRL connect to database to write\n",
    "    partition_name = \"silver_lms_loan_daily_\" + snapshot_date_str.replace('-','_') + '.parquet'\n",
    "    filepath = silver_loan_daily_directory + partition_name\n",
    "    df.write.mode(\"overwrite\").parquet(filepath)\n",
    "    print('saved to:', filepath)\n",
    "    \n",
    "    return df\n",
    "\n",
    "snapshotdate = \"2023-01-01\"\n",
    "process_silver_lms_table(snapshotdate, \n",
    "                         \"datamart/bronze/lms/\", \n",
    "                         \"datamart/silver/lms/\", \n",
    "                         spark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "3bec3b45-3ca9-49be-aed6-c7d483b974aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loan_id</th>\n",
       "      <th>Customer_ID</th>\n",
       "      <th>loan_start_date</th>\n",
       "      <th>tenure</th>\n",
       "      <th>installment_num</th>\n",
       "      <th>loan_amt</th>\n",
       "      <th>due_amt</th>\n",
       "      <th>paid_amt</th>\n",
       "      <th>overdue_amt</th>\n",
       "      <th>balance</th>\n",
       "      <th>snapshot_date</th>\n",
       "      <th>mob</th>\n",
       "      <th>installments_missed</th>\n",
       "      <th>first_missed_date</th>\n",
       "      <th>dpd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CUS_0x1037_2023_01_01</td>\n",
       "      <td>CUS_0x1037</td>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CUS_0x1069_2023_01_01</td>\n",
       "      <td>CUS_0x1069</td>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CUS_0x114a_2023_01_01</td>\n",
       "      <td>CUS_0x114a</td>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CUS_0x1184_2023_01_01</td>\n",
       "      <td>CUS_0x1184</td>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CUS_0x1297_2023_01_01</td>\n",
       "      <td>CUS_0x1297</td>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>525</th>\n",
       "      <td>CUS_0xe98_2023_01_01</td>\n",
       "      <td>CUS_0xe98</td>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>526</th>\n",
       "      <td>CUS_0xea6_2023_01_01</td>\n",
       "      <td>CUS_0xea6</td>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>527</th>\n",
       "      <td>CUS_0xed3_2023_01_01</td>\n",
       "      <td>CUS_0xed3</td>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>528</th>\n",
       "      <td>CUS_0xed8_2023_01_01</td>\n",
       "      <td>CUS_0xed8</td>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>529</th>\n",
       "      <td>CUS_0xfc9_2023_01_01</td>\n",
       "      <td>CUS_0xfc9</td>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>530 rows Ã— 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   loan_id Customer_ID loan_start_date  tenure  \\\n",
       "0    CUS_0x1037_2023_01_01  CUS_0x1037      2023-01-01      10   \n",
       "1    CUS_0x1069_2023_01_01  CUS_0x1069      2023-01-01      10   \n",
       "2    CUS_0x114a_2023_01_01  CUS_0x114a      2023-01-01      10   \n",
       "3    CUS_0x1184_2023_01_01  CUS_0x1184      2023-01-01      10   \n",
       "4    CUS_0x1297_2023_01_01  CUS_0x1297      2023-01-01      10   \n",
       "..                     ...         ...             ...     ...   \n",
       "525   CUS_0xe98_2023_01_01   CUS_0xe98      2023-01-01      10   \n",
       "526   CUS_0xea6_2023_01_01   CUS_0xea6      2023-01-01      10   \n",
       "527   CUS_0xed3_2023_01_01   CUS_0xed3      2023-01-01      10   \n",
       "528   CUS_0xed8_2023_01_01   CUS_0xed8      2023-01-01      10   \n",
       "529   CUS_0xfc9_2023_01_01   CUS_0xfc9      2023-01-01      10   \n",
       "\n",
       "     installment_num  loan_amt  due_amt  paid_amt  overdue_amt  balance  \\\n",
       "0                  0   10000.0      0.0       0.0          0.0  10000.0   \n",
       "1                  0   10000.0      0.0       0.0          0.0  10000.0   \n",
       "2                  0   10000.0      0.0       0.0          0.0  10000.0   \n",
       "3                  0   10000.0      0.0       0.0          0.0  10000.0   \n",
       "4                  0   10000.0      0.0       0.0          0.0  10000.0   \n",
       "..               ...       ...      ...       ...          ...      ...   \n",
       "525                0   10000.0      0.0       0.0          0.0  10000.0   \n",
       "526                0   10000.0      0.0       0.0          0.0  10000.0   \n",
       "527                0   10000.0      0.0       0.0          0.0  10000.0   \n",
       "528                0   10000.0      0.0       0.0          0.0  10000.0   \n",
       "529                0   10000.0      0.0       0.0          0.0  10000.0   \n",
       "\n",
       "    snapshot_date  mob  installments_missed first_missed_date  dpd  \n",
       "0      2023-01-01    0                    0              None    0  \n",
       "1      2023-01-01    0                    0              None    0  \n",
       "2      2023-01-01    0                    0              None    0  \n",
       "3      2023-01-01    0                    0              None    0  \n",
       "4      2023-01-01    0                    0              None    0  \n",
       "..            ...  ...                  ...               ...  ...  \n",
       "525    2023-01-01    0                    0              None    0  \n",
       "526    2023-01-01    0                    0              None    0  \n",
       "527    2023-01-01    0                    0              None    0  \n",
       "528    2023-01-01    0                    0              None    0  \n",
       "529    2023-01-01    0                    0              None    0  \n",
       "\n",
       "[530 rows x 15 columns]"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_parquet(\"datamart/silver/lms/silver_lms_loan_daily_2023_01_01.parquet\")\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "1dfafb65-bec0-4578-98e1-692c62fd8500",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 12500 entries, 0 to 12499\n",
      "Data columns (total 22 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   Customer_ID               12500 non-null  object \n",
      " 1   Annual_Income             12500 non-null  object \n",
      " 2   Monthly_Inhand_Salary     12500 non-null  float64\n",
      " 3   Num_Bank_Accounts         12500 non-null  int64  \n",
      " 4   Num_Credit_Card           12500 non-null  int64  \n",
      " 5   Interest_Rate             12500 non-null  int64  \n",
      " 6   Num_of_Loan               12500 non-null  object \n",
      " 7   Type_of_Loan              11074 non-null  object \n",
      " 8   Delay_from_due_date       12500 non-null  int64  \n",
      " 9   Num_of_Delayed_Payment    12500 non-null  object \n",
      " 10  Changed_Credit_Limit      12500 non-null  object \n",
      " 11  Num_Credit_Inquiries      12500 non-null  float64\n",
      " 12  Credit_Mix                12500 non-null  object \n",
      " 13  Outstanding_Debt          12500 non-null  object \n",
      " 14  Credit_Utilization_Ratio  12500 non-null  float64\n",
      " 15  Credit_History_Age        12500 non-null  object \n",
      " 16  Payment_of_Min_Amount     12500 non-null  object \n",
      " 17  Total_EMI_per_month       12500 non-null  float64\n",
      " 18  Amount_invested_monthly   12500 non-null  object \n",
      " 19  Payment_Behaviour         12500 non-null  object \n",
      " 20  Monthly_Balance           12500 non-null  object \n",
      " 21  snapshot_date             12500 non-null  object \n",
      "dtypes: float64(4), int64(4), object(14)\n",
      "memory usage: 2.1+ MB\n"
     ]
    }
   ],
   "source": [
    "financials_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b7d453f-20eb-4e0d-a8cd-7e56dc69ffb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # clickstream\n",
    "#     column_type_map = {\"fe_1\": IntegerType(),\n",
    "#                        'fe_2': IntegerType(),\n",
    "#                        'fe_3': IntegerType(),\n",
    "#                        'fe_4': IntegerType(),\n",
    "#                        'fe_5': IntegerType(),\n",
    "#                        'fe_6': IntegerType(),\n",
    "#                        'fe_7': IntegerType(),\n",
    "#                        'fe_8': IntegerType(),\n",
    "#                        'fe_9': IntegerType(),\n",
    "#                        'fe_10': IntegerType(),\n",
    "#                        'fe_11': IntegerType(),\n",
    "#                        'fe_12': IntegerType(),\n",
    "#                        'fe_13': IntegerType(),\n",
    "#                        'fe_14': IntegerType(),\n",
    "#                        'fe_15': IntegerType(),\n",
    "#                        'fe_16': IntegerType(),\n",
    "#                        'fe_17': IntegerType(),\n",
    "#                        'fe_18': IntegerType(),\n",
    "#                        'fe_19': IntegerType(),\n",
    "#                        'fe_20': IntegerType(),\n",
    "#                        \"Customer_ID\": StringType(),\n",
    "#                        \"snapshot_date\": DateType()\n",
    "#                     }\n",
    "\n",
    "# # attributes\n",
    "#         column_type_map = {\"Customer_ID\": StringType(),\n",
    "#                            \"Name\": IntegerType(),\n",
    "#                            'Age': IntegerType(),\n",
    "#                            'SSN': IntegerType(),\n",
    "#                            \"snapshot_date\": DateType()\n",
    "#                           }\n",
    "\n",
    "# financial\n",
    "    # columns_type_map = {'Customer_ID': StringType(),\n",
    "    #                     'Annual_Income': FloatType(),\n",
    "    #                     'Monthly_Inhand_Salary': FloatType(),\n",
    "    #                     'Num_Bank_Accounts': IntegerType(),\n",
    "    #                     'Num_Credit_Card': IntegerType(),\n",
    "    #                     'Interest_Rate': IntegerType(),\n",
    "    #                     'Num_of_Loan': IntegerType(),\n",
    "    #                     'Type_of_Loan': StringType(),\n",
    "    #                     'Delay_from_due_date': IntegerType(),\n",
    "    #                     'Num_of_Delayed_Payment': IntegerType(),\n",
    "    #                     'Changed_Credit_Limit': FloatType(),\n",
    "    #                     'Num_Credit_Inquiries': FloatType(),\n",
    "    #                     'Credit_Mix': StringType(),\n",
    "    #                     'Outstanding_Debt': FloatType(),\n",
    "    #                     'Credit_Utilization_Ratio': FloatType(),\n",
    "    #                     'Credit_History_Age': StringType(),\n",
    "    #                     'Payment_of_Min_Amount': StringType(),\n",
    "    #                     'Total_EMI_per_month': FloatType(),\n",
    "    #                     'Amount_invested_monthly': FloatType(),\n",
    "    #                     'Payment_Behaviour': StringType(),\n",
    "    #                     'Monthly_Balance': FloatType(),\n",
    "    #                     'snapshot_date': DateType()\n",
    "    #                     }\n",
    "\n",
    "# loan\n",
    "    # column_type_map = {\n",
    "    #         \"loan_id\": StringType(),\n",
    "    #         \"Customer_ID\": StringType(),\n",
    "    #         \"loan_start_date\": DateType(),\n",
    "    #         \"tenure\": IntegerType(),\n",
    "    #         \"installment_num\": IntegerType(),\n",
    "    #         \"loan_amt\": FloatType(),\n",
    "    #         \"due_amt\": FloatType(),\n",
    "    #         \"paid_amt\": FloatType(),\n",
    "    #         \"overdue_amt\": FloatType(),\n",
    "    #         \"balance\": FloatType(),\n",
    "    #         \"snapshot_date\": DateType(),\n",
    "    #     }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b020054d-6bb3-4c67-b748-d689556a4f5a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "c5b791d6-8fc5-4112-99dd-0429bc471c01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 215376 entries, 0 to 215375\n",
      "Data columns (total 22 columns):\n",
      " #   Column         Non-Null Count   Dtype \n",
      "---  ------         --------------   ----- \n",
      " 0   fe_1           215376 non-null  int64 \n",
      " 1   fe_2           215376 non-null  int64 \n",
      " 2   fe_3           215376 non-null  int64 \n",
      " 3   fe_4           215376 non-null  int64 \n",
      " 4   fe_5           215376 non-null  int64 \n",
      " 5   fe_6           215376 non-null  int64 \n",
      " 6   fe_7           215376 non-null  int64 \n",
      " 7   fe_8           215376 non-null  int64 \n",
      " 8   fe_9           215376 non-null  int64 \n",
      " 9   fe_10          215376 non-null  int64 \n",
      " 10  fe_11          215376 non-null  int64 \n",
      " 11  fe_12          215376 non-null  int64 \n",
      " 12  fe_13          215376 non-null  int64 \n",
      " 13  fe_14          215376 non-null  int64 \n",
      " 14  fe_15          215376 non-null  int64 \n",
      " 15  fe_16          215376 non-null  int64 \n",
      " 16  fe_17          215376 non-null  int64 \n",
      " 17  fe_18          215376 non-null  int64 \n",
      " 18  fe_19          215376 non-null  int64 \n",
      " 19  fe_20          215376 non-null  int64 \n",
      " 20  Customer_ID    215376 non-null  object\n",
      " 21  snapshot_date  215376 non-null  object\n",
      "dtypes: int64(20), object(2)\n",
      "memory usage: 36.2+ MB\n"
     ]
    }
   ],
   "source": [
    "# clickstream_df = pd.read_csv(clickstream)\n",
    "clickstream_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "ee2560d5-69b9-4a50-83f1-5a38a83560b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total clickstream customers: 8974\n",
      "Total attribute customers: 12500\n",
      "Matched customers: 8974\n",
      "Missing in attributes: 0\n",
      "Missing in clickstream: 3526\n"
     ]
    }
   ],
   "source": [
    "# Get unique IDs\n",
    "click_cust = set(clickstream_df[\"Customer_ID\"].unique())\n",
    "attr_cust = set(attributes_df[\"Customer_ID\"].unique())\n",
    "\n",
    "# 1. Customers in clickstream but NOT in attributes\n",
    "missing_in_attr = click_cust - attr_cust\n",
    "\n",
    "# 2. Customers in attributes but NOT in clickstream\n",
    "missing_in_click = attr_cust - click_cust\n",
    "\n",
    "# 3. Customers present in both\n",
    "matched = click_cust & attr_cust\n",
    "\n",
    "print(f\"Total clickstream customers: {len(click_cust)}\")\n",
    "print(f\"Total attribute customers: {len(attr_cust)}\")\n",
    "print(f\"Matched customers: {len(matched)}\")\n",
    "print(f\"Missing in attributes: {len(missing_in_attr)}\")\n",
    "print(f\"Missing in clickstream: {len(missing_in_click)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "9b295c3e-789e-45e8-9489-47d591349041",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['CUS_0x1000', 'CUS_0x1009', 'CUS_0x100b', ..., 'CUS_0xff6',\n",
       "       'CUS_0xffc', 'CUS_0xffd'], shape=(12500,), dtype=object)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "af02313b-ee08-496e-866b-491e48d8dba7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fe_1</th>\n",
       "      <th>fe_2</th>\n",
       "      <th>fe_3</th>\n",
       "      <th>fe_4</th>\n",
       "      <th>fe_5</th>\n",
       "      <th>fe_6</th>\n",
       "      <th>fe_7</th>\n",
       "      <th>fe_8</th>\n",
       "      <th>fe_9</th>\n",
       "      <th>fe_10</th>\n",
       "      <th>...</th>\n",
       "      <th>fe_13</th>\n",
       "      <th>fe_14</th>\n",
       "      <th>fe_15</th>\n",
       "      <th>fe_16</th>\n",
       "      <th>fe_17</th>\n",
       "      <th>fe_18</th>\n",
       "      <th>fe_19</th>\n",
       "      <th>fe_20</th>\n",
       "      <th>Customer_ID</th>\n",
       "      <th>snapshot_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63</td>\n",
       "      <td>118</td>\n",
       "      <td>80</td>\n",
       "      <td>121</td>\n",
       "      <td>55</td>\n",
       "      <td>193</td>\n",
       "      <td>111</td>\n",
       "      <td>112</td>\n",
       "      <td>-101</td>\n",
       "      <td>83</td>\n",
       "      <td>...</td>\n",
       "      <td>-16</td>\n",
       "      <td>-81</td>\n",
       "      <td>-126</td>\n",
       "      <td>114</td>\n",
       "      <td>35</td>\n",
       "      <td>85</td>\n",
       "      <td>-73</td>\n",
       "      <td>76</td>\n",
       "      <td>CUS_0x1037</td>\n",
       "      <td>2023-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-108</td>\n",
       "      <td>182</td>\n",
       "      <td>123</td>\n",
       "      <td>4</td>\n",
       "      <td>-56</td>\n",
       "      <td>27</td>\n",
       "      <td>25</td>\n",
       "      <td>-6</td>\n",
       "      <td>284</td>\n",
       "      <td>222</td>\n",
       "      <td>...</td>\n",
       "      <td>-14</td>\n",
       "      <td>-96</td>\n",
       "      <td>200</td>\n",
       "      <td>35</td>\n",
       "      <td>130</td>\n",
       "      <td>94</td>\n",
       "      <td>111</td>\n",
       "      <td>75</td>\n",
       "      <td>CUS_0x1069</td>\n",
       "      <td>2023-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-13</td>\n",
       "      <td>8</td>\n",
       "      <td>87</td>\n",
       "      <td>166</td>\n",
       "      <td>214</td>\n",
       "      <td>-98</td>\n",
       "      <td>215</td>\n",
       "      <td>152</td>\n",
       "      <td>129</td>\n",
       "      <td>139</td>\n",
       "      <td>...</td>\n",
       "      <td>26</td>\n",
       "      <td>86</td>\n",
       "      <td>171</td>\n",
       "      <td>125</td>\n",
       "      <td>-130</td>\n",
       "      <td>354</td>\n",
       "      <td>17</td>\n",
       "      <td>302</td>\n",
       "      <td>CUS_0x114a</td>\n",
       "      <td>2023-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-85</td>\n",
       "      <td>45</td>\n",
       "      <td>200</td>\n",
       "      <td>89</td>\n",
       "      <td>128</td>\n",
       "      <td>54</td>\n",
       "      <td>76</td>\n",
       "      <td>51</td>\n",
       "      <td>61</td>\n",
       "      <td>139</td>\n",
       "      <td>...</td>\n",
       "      <td>172</td>\n",
       "      <td>96</td>\n",
       "      <td>174</td>\n",
       "      <td>163</td>\n",
       "      <td>37</td>\n",
       "      <td>207</td>\n",
       "      <td>180</td>\n",
       "      <td>118</td>\n",
       "      <td>CUS_0x1184</td>\n",
       "      <td>2023-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>55</td>\n",
       "      <td>120</td>\n",
       "      <td>226</td>\n",
       "      <td>-86</td>\n",
       "      <td>253</td>\n",
       "      <td>97</td>\n",
       "      <td>107</td>\n",
       "      <td>68</td>\n",
       "      <td>103</td>\n",
       "      <td>126</td>\n",
       "      <td>...</td>\n",
       "      <td>76</td>\n",
       "      <td>43</td>\n",
       "      <td>183</td>\n",
       "      <td>159</td>\n",
       "      <td>-26</td>\n",
       "      <td>104</td>\n",
       "      <td>118</td>\n",
       "      <td>184</td>\n",
       "      <td>CUS_0x1297</td>\n",
       "      <td>2023-01-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   fe_1  fe_2  fe_3  fe_4  fe_5  fe_6  fe_7  fe_8  fe_9  fe_10  ...  fe_13  \\\n",
       "0    63   118    80   121    55   193   111   112  -101     83  ...    -16   \n",
       "1  -108   182   123     4   -56    27    25    -6   284    222  ...    -14   \n",
       "2   -13     8    87   166   214   -98   215   152   129    139  ...     26   \n",
       "3   -85    45   200    89   128    54    76    51    61    139  ...    172   \n",
       "4    55   120   226   -86   253    97   107    68   103    126  ...     76   \n",
       "\n",
       "   fe_14  fe_15  fe_16  fe_17  fe_18  fe_19  fe_20  Customer_ID  snapshot_date  \n",
       "0    -81   -126    114     35     85    -73     76   CUS_0x1037     2023-01-01  \n",
       "1    -96    200     35    130     94    111     75   CUS_0x1069     2023-01-01  \n",
       "2     86    171    125   -130    354     17    302   CUS_0x114a     2023-01-01  \n",
       "3     96    174    163     37    207    180    118   CUS_0x1184     2023-01-01  \n",
       "4     43    183    159    -26    104    118    184   CUS_0x1297     2023-01-01  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clickstream_df = pd.read_csv(clickstream)\n",
    "clickstream_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2b003ffa-3ea2-4efd-bb7e-3f4ba6d2930c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Customer_ID</th>\n",
       "      <th>Name</th>\n",
       "      <th>Age</th>\n",
       "      <th>SSN</th>\n",
       "      <th>Occupation</th>\n",
       "      <th>snapshot_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CUS_0x1000</td>\n",
       "      <td>Alistair Barrf</td>\n",
       "      <td>18</td>\n",
       "      <td>913-74-1218</td>\n",
       "      <td>Lawyer</td>\n",
       "      <td>2023-05-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CUS_0x1009</td>\n",
       "      <td>Arunah</td>\n",
       "      <td>26</td>\n",
       "      <td>063-67-6938</td>\n",
       "      <td>Mechanic</td>\n",
       "      <td>2025-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CUS_0x100b</td>\n",
       "      <td>Shirboni</td>\n",
       "      <td>19</td>\n",
       "      <td>#F%$D@*&amp;8</td>\n",
       "      <td>Media_Manager</td>\n",
       "      <td>2024-03-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CUS_0x1011</td>\n",
       "      <td>Schneyerh</td>\n",
       "      <td>44</td>\n",
       "      <td>793-05-8223</td>\n",
       "      <td>Doctor</td>\n",
       "      <td>2023-11-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CUS_0x1013</td>\n",
       "      <td>Cameront</td>\n",
       "      <td>44</td>\n",
       "      <td>930-49-9615</td>\n",
       "      <td>Mechanic</td>\n",
       "      <td>2023-12-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Customer_ID            Name Age          SSN     Occupation snapshot_date\n",
       "0  CUS_0x1000  Alistair Barrf  18  913-74-1218         Lawyer    2023-05-01\n",
       "1  CUS_0x1009          Arunah  26  063-67-6938       Mechanic    2025-01-01\n",
       "2  CUS_0x100b        Shirboni  19    #F%$D@*&8  Media_Manager    2024-03-01\n",
       "3  CUS_0x1011       Schneyerh  44  793-05-8223         Doctor    2023-11-01\n",
       "4  CUS_0x1013        Cameront  44  930-49-9615       Mechanic    2023-12-01"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attributes_df = pd.read_csv(attributes)\n",
    "attributes_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "88cfd5f0-8947-4349-99a3-4a670f8f27d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Customer_ID</th>\n",
       "      <th>Annual_Income</th>\n",
       "      <th>Monthly_Inhand_Salary</th>\n",
       "      <th>Num_Bank_Accounts</th>\n",
       "      <th>Num_Credit_Card</th>\n",
       "      <th>Interest_Rate</th>\n",
       "      <th>Num_of_Loan</th>\n",
       "      <th>Type_of_Loan</th>\n",
       "      <th>Delay_from_due_date</th>\n",
       "      <th>Num_of_Delayed_Payment</th>\n",
       "      <th>...</th>\n",
       "      <th>Credit_Mix</th>\n",
       "      <th>Outstanding_Debt</th>\n",
       "      <th>Credit_Utilization_Ratio</th>\n",
       "      <th>Credit_History_Age</th>\n",
       "      <th>Payment_of_Min_Amount</th>\n",
       "      <th>Total_EMI_per_month</th>\n",
       "      <th>Amount_invested_monthly</th>\n",
       "      <th>Payment_Behaviour</th>\n",
       "      <th>Monthly_Balance</th>\n",
       "      <th>snapshot_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CUS_0x1000</td>\n",
       "      <td>30625.94</td>\n",
       "      <td>2706.161667</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>27</td>\n",
       "      <td>2</td>\n",
       "      <td>Credit-Builder Loan, and Home Equity Loan</td>\n",
       "      <td>57</td>\n",
       "      <td>26</td>\n",
       "      <td>...</td>\n",
       "      <td>Bad</td>\n",
       "      <td>1562.91</td>\n",
       "      <td>30.077191</td>\n",
       "      <td>10 Years and 9 Months</td>\n",
       "      <td>Yes</td>\n",
       "      <td>42.941090</td>\n",
       "      <td>77.31427572208112</td>\n",
       "      <td>High_spent_Medium_value_payments</td>\n",
       "      <td>400.36080052211616</td>\n",
       "      <td>2023-05-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CUS_0x1009</td>\n",
       "      <td>52312.68_</td>\n",
       "      <td>4250.390000</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>17</td>\n",
       "      <td>4</td>\n",
       "      <td>Not Specified, Home Equity Loan, Credit-Builde...</td>\n",
       "      <td>5</td>\n",
       "      <td>18</td>\n",
       "      <td>...</td>\n",
       "      <td>_</td>\n",
       "      <td>202.68</td>\n",
       "      <td>40.286997</td>\n",
       "      <td>31 Years and 0 Months</td>\n",
       "      <td>Yes</td>\n",
       "      <td>108.366467</td>\n",
       "      <td>58.66019164829086</td>\n",
       "      <td>High_spent_Medium_value_payments</td>\n",
       "      <td>508.01234122645366</td>\n",
       "      <td>2025-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CUS_0x100b</td>\n",
       "      <td>113781.38999999998</td>\n",
       "      <td>9549.782500</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>Good</td>\n",
       "      <td>1030.2</td>\n",
       "      <td>28.592943</td>\n",
       "      <td>15 Years and 10 Months</td>\n",
       "      <td>No</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>617.0792665202719</td>\n",
       "      <td>High_spent_Small_value_payments</td>\n",
       "      <td>597.8989834797281</td>\n",
       "      <td>2024-03-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CUS_0x1011</td>\n",
       "      <td>58918.47</td>\n",
       "      <td>5208.872500</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>Student Loan, Credit-Builder Loan, and Debt Co...</td>\n",
       "      <td>27</td>\n",
       "      <td>13</td>\n",
       "      <td>...</td>\n",
       "      <td>Standard</td>\n",
       "      <td>473.14</td>\n",
       "      <td>27.829959</td>\n",
       "      <td>15 Years and 10 Months</td>\n",
       "      <td>Yes</td>\n",
       "      <td>123.434939</td>\n",
       "      <td>383.35084463651407</td>\n",
       "      <td>Low_spent_Medium_value_payments</td>\n",
       "      <td>294.1014665671429</td>\n",
       "      <td>2023-11-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CUS_0x1013</td>\n",
       "      <td>98620.98</td>\n",
       "      <td>7962.415000</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>Student Loan, Debt Consolidation Loan, and Per...</td>\n",
       "      <td>12</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>Good</td>\n",
       "      <td>1233.51</td>\n",
       "      <td>26.524864</td>\n",
       "      <td>17 Years and 10 Months</td>\n",
       "      <td>No</td>\n",
       "      <td>228.018084</td>\n",
       "      <td>332.3337079767732</td>\n",
       "      <td>High_spent_Medium_value_payments</td>\n",
       "      <td>485.8897083704929</td>\n",
       "      <td>2023-12-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Customer_ID       Annual_Income  Monthly_Inhand_Salary  Num_Bank_Accounts  \\\n",
       "0  CUS_0x1000            30625.94            2706.161667                  6   \n",
       "1  CUS_0x1009           52312.68_            4250.390000                  6   \n",
       "2  CUS_0x100b  113781.38999999998            9549.782500                  1   \n",
       "3  CUS_0x1011            58918.47            5208.872500                  3   \n",
       "4  CUS_0x1013            98620.98            7962.415000                  3   \n",
       "\n",
       "   Num_Credit_Card  Interest_Rate Num_of_Loan  \\\n",
       "0                5             27           2   \n",
       "1                5             17           4   \n",
       "2                4              1           0   \n",
       "3                3             17           3   \n",
       "4                3              6           3   \n",
       "\n",
       "                                        Type_of_Loan  Delay_from_due_date  \\\n",
       "0          Credit-Builder Loan, and Home Equity Loan                   57   \n",
       "1  Not Specified, Home Equity Loan, Credit-Builde...                    5   \n",
       "2                                                NaN                   14   \n",
       "3  Student Loan, Credit-Builder Loan, and Debt Co...                   27   \n",
       "4  Student Loan, Debt Consolidation Loan, and Per...                   12   \n",
       "\n",
       "  Num_of_Delayed_Payment  ... Credit_Mix  Outstanding_Debt  \\\n",
       "0                     26  ...        Bad           1562.91   \n",
       "1                     18  ...          _            202.68   \n",
       "2                      8  ...       Good            1030.2   \n",
       "3                     13  ...   Standard            473.14   \n",
       "4                      9  ...       Good           1233.51   \n",
       "\n",
       "  Credit_Utilization_Ratio      Credit_History_Age  Payment_of_Min_Amount  \\\n",
       "0                30.077191   10 Years and 9 Months                    Yes   \n",
       "1                40.286997   31 Years and 0 Months                    Yes   \n",
       "2                28.592943  15 Years and 10 Months                     No   \n",
       "3                27.829959  15 Years and 10 Months                    Yes   \n",
       "4                26.524864  17 Years and 10 Months                     No   \n",
       "\n",
       "  Total_EMI_per_month Amount_invested_monthly  \\\n",
       "0           42.941090       77.31427572208112   \n",
       "1          108.366467       58.66019164829086   \n",
       "2            0.000000       617.0792665202719   \n",
       "3          123.434939      383.35084463651407   \n",
       "4          228.018084       332.3337079767732   \n",
       "\n",
       "                  Payment_Behaviour     Monthly_Balance snapshot_date  \n",
       "0  High_spent_Medium_value_payments  400.36080052211616    2023-05-01  \n",
       "1  High_spent_Medium_value_payments  508.01234122645366    2025-01-01  \n",
       "2   High_spent_Small_value_payments   597.8989834797281    2024-03-01  \n",
       "3   Low_spent_Medium_value_payments   294.1014665671429    2023-11-01  \n",
       "4  High_spent_Medium_value_payments   485.8897083704929    2023-12-01  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "financials_df = pd.read_csv(financials)\n",
    "financials_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f362cdbf-e629-4c30-9dfd-29902fc8792f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loan_id</th>\n",
       "      <th>Customer_ID</th>\n",
       "      <th>loan_start_date</th>\n",
       "      <th>tenure</th>\n",
       "      <th>installment_num</th>\n",
       "      <th>loan_amt</th>\n",
       "      <th>due_amt</th>\n",
       "      <th>paid_amt</th>\n",
       "      <th>overdue_amt</th>\n",
       "      <th>balance</th>\n",
       "      <th>snapshot_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CUS_0x1000_2023_05_01</td>\n",
       "      <td>CUS_0x1000</td>\n",
       "      <td>2023-05-01</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>10000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>2023-05-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CUS_0x1000_2023_05_01</td>\n",
       "      <td>CUS_0x1000</td>\n",
       "      <td>2023-05-01</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>10000</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9000.0</td>\n",
       "      <td>2023-06-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CUS_0x1000_2023_05_01</td>\n",
       "      <td>CUS_0x1000</td>\n",
       "      <td>2023-05-01</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>10000</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8000.0</td>\n",
       "      <td>2023-07-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CUS_0x1000_2023_05_01</td>\n",
       "      <td>CUS_0x1000</td>\n",
       "      <td>2023-05-01</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>10000</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>8000.0</td>\n",
       "      <td>2023-08-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CUS_0x1000_2023_05_01</td>\n",
       "      <td>CUS_0x1000</td>\n",
       "      <td>2023-05-01</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>10000</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6000.0</td>\n",
       "      <td>2023-09-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 loan_id Customer_ID loan_start_date  tenure  installment_num  \\\n",
       "0  CUS_0x1000_2023_05_01  CUS_0x1000      2023-05-01      10                0   \n",
       "1  CUS_0x1000_2023_05_01  CUS_0x1000      2023-05-01      10                1   \n",
       "2  CUS_0x1000_2023_05_01  CUS_0x1000      2023-05-01      10                2   \n",
       "3  CUS_0x1000_2023_05_01  CUS_0x1000      2023-05-01      10                3   \n",
       "4  CUS_0x1000_2023_05_01  CUS_0x1000      2023-05-01      10                4   \n",
       "\n",
       "   loan_amt  due_amt  paid_amt  overdue_amt  balance snapshot_date  \n",
       "0     10000      0.0       0.0          0.0  10000.0    2023-05-01  \n",
       "1     10000   1000.0    1000.0          0.0   9000.0    2023-06-01  \n",
       "2     10000   1000.0    1000.0          0.0   8000.0    2023-07-01  \n",
       "3     10000   1000.0       0.0       1000.0   8000.0    2023-08-01  \n",
       "4     10000   1000.0    2000.0          0.0   6000.0    2023-09-01  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loan_daily_df = pd.read_csv(loan_daily)\n",
    "loan_daily_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "082d4c2c-56f5-48ee-ab2a-d3e7a15538d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2024-12-01'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clickstream_df.snapshot_date.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e52b13d4-f088-4f2b-bfed-e16e1c1e9f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_bronze_table(snapshot_date_str, bronze_lms_directory, spark):\n",
    "    # prepare arguments\n",
    "    snapshot_date = datetime.strptime(snapshot_date_str, \"%Y-%m-%d\")\n",
    "    \n",
    "    # connect to source back end - IRL connect to back end source system\n",
    "    csv_file_path = \"data/lms_loan_daily.csv\"\n",
    "\n",
    "    # load data - IRL ingest from back end source system\n",
    "    df = spark.read.csv(csv_file_path, header=True, inferSchema=True).filter(col('snapshot_date') == snapshot_date)\n",
    "    print(snapshot_date_str + 'row count:', df.count())\n",
    "\n",
    "    # save bronze table to datamart - IRL connect to database to write\n",
    "    partition_name = \"bronze_loan_daily_\" + snapshot_date_str.replace('-','_') + '.csv'\n",
    "    filepath = bronze_lms_directory + partition_name\n",
    "    df.toPandas().to_csv(filepath, index=False)\n",
    "    print('saved to:', filepath)\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "993d1245-63b5-4abe-8319-9150c74a2a58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-01-01row count: 530\n",
      "saved to: datamart/bronze/lms/bronze_loan_daily_2023_01_01.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[loan_id: string, Customer_ID: string, loan_start_date: date, tenure: int, installment_num: int, loan_amt: int, due_amt: double, paid_amt: double, overdue_amt: double, balance: double, snapshot_date: date]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bronze_lms_directory = \"datamart/bronze/lms/\"\n",
    "snapshotdate = \"2023-01-01\"\n",
    "\n",
    "spark = pyspark.sql.SparkSession.builder \\\n",
    "        .appName(\"dev\") \\\n",
    "        .master(\"local[*]\") \\\n",
    "        .getOrCreate()\n",
    "\n",
    "process_bronze_table(snapshotdate, bronze_lms_directory, spark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6bbb4eb1-7531-48ec-aed2-9810c6aef64a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_silver_table(snapshot_date_str, bronze_lms_directory, silver_loan_daily_directory, spark):\n",
    "    # prepare arguments\n",
    "    snapshot_date = datetime.strptime(snapshot_date_str, \"%Y-%m-%d\")\n",
    "    \n",
    "    # connect to bronze table\n",
    "    partition_name = \"bronze_loan_daily_\" + snapshot_date_str.replace('-','_') + '.csv'\n",
    "    filepath = bronze_lms_directory + partition_name\n",
    "    df = spark.read.csv(filepath, header=True, inferSchema=True)\n",
    "    print('loaded from:', filepath, 'row count:', df.count())\n",
    "\n",
    "    # clean data: enforce schema / data type\n",
    "    # Dictionary specifying columns and their desired datatypes\n",
    "    column_type_map = {\n",
    "        \"loan_id\": StringType(),\n",
    "        \"Customer_ID\": StringType(),\n",
    "        \"loan_start_date\": DateType(),\n",
    "        \"tenure\": IntegerType(),\n",
    "        \"installment_num\": IntegerType(),\n",
    "        \"loan_amt\": FloatType(),\n",
    "        \"due_amt\": FloatType(),\n",
    "        \"paid_amt\": FloatType(),\n",
    "        \"overdue_amt\": FloatType(),\n",
    "        \"balance\": FloatType(),\n",
    "        \"snapshot_date\": DateType(),\n",
    "    }\n",
    "\n",
    "    for column, new_type in column_type_map.items():\n",
    "        df = df.withColumn(column, col(column).cast(new_type))\n",
    "\n",
    "    # augment data: add month on book\n",
    "    df = df.withColumn(\"mob\", col(\"installment_num\").cast(IntegerType()))\n",
    "\n",
    "    # augment data: add days past due\n",
    "    df = df.withColumn(\"installments_missed\", F.ceil(col(\"overdue_amt\") / col(\"due_amt\")).cast(IntegerType())).fillna(0)\n",
    "    df = df.withColumn(\"first_missed_date\", F.when(col(\"installments_missed\") > 0, F.add_months(col(\"snapshot_date\"), -1 * col(\"installments_missed\"))).cast(DateType()))\n",
    "    df = df.withColumn(\"dpd\", F.when(col(\"overdue_amt\") > 0.0, F.datediff(col(\"snapshot_date\"), col(\"first_missed_date\"))).otherwise(0).cast(IntegerType()))\n",
    "\n",
    "    # save silver table - IRL connect to database to write\n",
    "    partition_name = \"silver_loan_daily_\" + snapshot_date_str.replace('-','_') + '.parquet'\n",
    "    filepath = silver_loan_daily_directory + partition_name\n",
    "    df.write.mode(\"overwrite\").parquet(filepath)\n",
    "    # df.toPandas().to_parquet(filepath,\n",
    "    #           compression='gzip')\n",
    "    print('saved to:', filepath)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ec623b6-2758-49cc-9ee7-2c8fd70271ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5b2d793-834a-459f-abc8-00a9687a1cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_labels_gold_table(snapshot_date_str, silver_loan_daily_directory, gold_label_store_directory, spark, dpd, mob):\n",
    "    \n",
    "    # prepare arguments\n",
    "    snapshot_date = datetime.strptime(snapshot_date_str, \"%Y-%m-%d\")\n",
    "    \n",
    "    # connect to bronze table\n",
    "    partition_name = \"silver_loan_daily_\" + snapshot_date_str.replace('-','_') + '.parquet'\n",
    "    filepath = silver_loan_daily_directory + partition_name\n",
    "    df = spark.read.parquet(filepath)\n",
    "    print('loaded from:', filepath, 'row count:', df.count())\n",
    "\n",
    "    # get customer at mob\n",
    "    df = df.filter(col(\"mob\") == mob)\n",
    "\n",
    "    # get label\n",
    "    df = df.withColumn(\"label\", F.when(col(\"dpd\") >= dpd, 1).otherwise(0).cast(IntegerType()))\n",
    "    df = df.withColumn(\"label_def\", F.lit(str(dpd)+'dpd_'+str(mob)+'mob').cast(StringType()))\n",
    "\n",
    "    # select columns to save\n",
    "    df = df.select(\"loan_id\", \"Customer_ID\", \"label\", \"label_def\", \"snapshot_date\")\n",
    "\n",
    "    # save gold table - IRL connect to database to write\n",
    "    partition_name = \"gold_label_store_\" + snapshot_date_str.replace('-','_') + '.parquet'\n",
    "    filepath = gold_label_store_directory + partition_name\n",
    "    df.write.mode(\"overwrite\").parquet(filepath)\n",
    "    # df.toPandas().to_parquet(filepath,\n",
    "    #           compression='gzip')\n",
    "    print('saved to:', filepath)\n",
    "    \n",
    "    return df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
